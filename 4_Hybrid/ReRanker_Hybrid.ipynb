{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install --upgrade sentence-transformers\n",
    "!pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffff91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import CrossEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers.util import mine_hard_negatives\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.cross_encoder.losses import BinaryCrossEntropyLoss\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainer\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70da3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3422ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl'\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
    "PATH_QUERY_TRAIN_BM25 = 'df_train_bm25_50.csv' #MODIFY PATH\n",
    "PATH_QUERY_DEV_BM25 = 'df_dev_bm25_50.csv' #MODIFY PATH\n",
    "PATH_QUERY_TRAIN_GRANITE = 'granite_top75_train.json' #MODIFY PATH\n",
    "PATH_QUERY_DEV_GRANITE = 'granite_top75_dev.json' #MODIFY PATH\n",
    "\n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)\n",
    "df_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')\n",
    "df_train_bm25 = pd.read_csv(PATH_QUERY_TRAIN_BM25, sep = ',')\n",
    "df_dev_bm25 = pd.read_csv(PATH_QUERY_DEV_BM25, sep = ',')\n",
    "\n",
    "df_dev_bm25[\"bm25_topk\"] = df_dev_bm25[\"bm25_topk\"].apply(ast.literal_eval)\n",
    "df_train_bm25[\"bm25_topk\"] = df_train_bm25[\"bm25_topk\"].apply(ast.literal_eval)\n",
    "\n",
    "df_train_granite = pd.read_json(PATH_QUERY_TRAIN_GRANITE)\n",
    "df_dev_granite = pd.read_json(PATH_QUERY_DEV_GRANITE)\n",
    "\n",
    "df_train = pd.merge(df_train_granite, df_train[['post_id', 'tweet_text']], left_on='tweet', right_on='post_id', how='left').drop(columns='post_id')\n",
    "df_dev = pd.merge(df_dev_granite, df_dev[['post_id', 'tweet_text']], left_on='tweet', right_on='post_id', how='left').drop(columns='post_id')\n",
    "\n",
    "df_train = pd.merge(df_train_granite, df_dev_bm25, left_on='tweet', right_on='post_id', how='left').drop(columns='post_id')\n",
    "df_dev = pd.merge(df_dev_granite, df_dev_bm25, left_on='tweet', right_on='post_id', how='left').drop(columns='post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d3c7c5f-efc1-400c-9087-cbaf837997e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>gold_paper</th>\n",
       "      <th>retrieved</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[jrqlhjsm, hg3xpej0, vccct6hq, mamtxi9v, styav...</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[25aj8rj5, gatxuwz7, 59up4v56, styavbvi, 6sy80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, mm4kgvt1, qtzhfnr6, sjkni2uc, kiq6x...</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, 9dlaaye8, iu1d9i57, d06np...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[6hnts5l2, ujq9mxk7, gruir7aw, zhh2c89o, 21lbb...</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[tz2shoso, o877uul1, m1sf159a, sgo76prc, gruir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, u43jmpyx, 8hvve871, 121p2shq, h7n8w...</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, k0f4cwig, ihgxt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[ybwwmyqy, lzddnb8j, ierqfgo5, qh6rif48, sxx3y...</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[lzddnb8j, ouvq2wpq, sxx3yid9, vabb2f26, y9fqa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet gold_paper                                          retrieved  \\\n",
       "0     16   3qvh482o  [jrqlhjsm, hg3xpej0, vccct6hq, mamtxi9v, styav...   \n",
       "1     69   r58aohnu  [r58aohnu, mm4kgvt1, qtzhfnr6, sjkni2uc, kiq6x...   \n",
       "2     73   sts48u9i  [6hnts5l2, ujq9mxk7, gruir7aw, zhh2c89o, 21lbb...   \n",
       "3     93   3sr2exq9  [3sr2exq9, u43jmpyx, 8hvve871, 121p2shq, h7n8w...   \n",
       "4     96   ybwwmyqy  [ybwwmyqy, lzddnb8j, ierqfgo5, qh6rif48, sxx3y...   \n",
       "\n",
       "                                          tweet_text  cord_uid  \\\n",
       "0  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2  I recall early on reading that researchers who...  sts48u9i   \n",
       "3  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk  \n",
       "0  [25aj8rj5, gatxuwz7, 59up4v56, styavbvi, 6sy80...  \n",
       "1  [r58aohnu, p0kg6dyz, 9dlaaye8, iu1d9i57, d06np...  \n",
       "2  [tz2shoso, o877uul1, m1sf159a, sgo76prc, gruir...  \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, k0f4cwig, ihgxt...  \n",
       "4  [lzddnb8j, ouvq2wpq, sxx3yid9, vabb2f26, y9fqa...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad924175",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIRECTORY = './reranker/'\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/static-retrieval-mrl-en-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d78d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2512/1201379260.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"gradient\",\n",
    "    breakpoint_threshold_amount=0.3\n",
    ")\n",
    "\n",
    "def semantic_chunking(text):\n",
    "    documents = text_splitter.create_documents([text])\n",
    "    chunks = [doc.page_content for doc in documents]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6a2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(MODEL_DIRECTORY, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19202e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 1400/1400 [02:13<00:00, 10.49it/s]\n"
     ]
    }
   ],
   "source": [
    "collection_dict = df_collection.set_index('cord_uid')['abstract'].to_dict()\n",
    "\n",
    "pairs = []\n",
    "query_indices = []\n",
    "uid_mappings = []\n",
    "\n",
    "for idx, row in tqdm(enumerate(df_dev.itertuples()), desc=\"Processing rows\", total=len(df_dev)):\n",
    "    query = row.tweet_text\n",
    "    candidate_uids = row.retrieved\n",
    "\n",
    "    for uid in candidate_uids[:25]:\n",
    "        abstract = collection_dict[uid]\n",
    "        chunks = semantic_chunking(abstract)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            pairs.append([query, chunk])\n",
    "            query_indices.append(idx)\n",
    "            uid_mappings.append(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ed290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = model.predict(pairs)\n",
    "\n",
    "query_results = [defaultdict(float) for _ in range(len(df_dev))]\n",
    "\n",
    "for idx, uid, score in zip(query_indices, uid_mappings, all_scores):\n",
    "    query_results[idx][uid] = max(query_results[idx][uid], score)\n",
    "\n",
    "reranked_uids = []\n",
    "\n",
    "for idx in range(len(df_dev)):\n",
    "    max_scores = query_results[idx]\n",
    "    sorted_uids = sorted(max_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    reranked_uids.append([uid for uid, _ in sorted_uids])\n",
    "\n",
    "df_dev['reranked'] = reranked_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74e4e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reciprocal_rank_fusion(list1, list2, k=40, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Compute Reciprocal Rank Fusion (RRF) score for two ranked lists.\n",
    "    \"\"\"\n",
    "    beta = 1 - alpha\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    for rank, uid in enumerate(list1):\n",
    "        scores[uid] += alpha / (k + rank)\n",
    "    for rank, uid in enumerate(list2):\n",
    "        scores[uid] += beta / (k + rank)\n",
    "\n",
    "    # Sort by highest score\n",
    "    sorted_uids = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [uid for uid, _ in sorted_uids[:5]]  # top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b28aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k=[1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36cc3ad7-f6b1-42fb-b1de-d656d3e83894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_parameter_tuning(df, a, b):\n",
    "    best = - 1\n",
    "    best_values = (-1, -1)\n",
    "    for k in tqdm(a):\n",
    "        for alpha in b:\n",
    "            df[\"result\"] = df.apply(\n",
    "                lambda x: reciprocal_rank_fusion(x[\"bm25_topk\"], x[\"reranked\"], k=k, alpha=alpha), axis=1\n",
    "            )\n",
    "            res = get_performance_mrr(df_dev, \"gold_paper\", \"result\")[5]\n",
    "            if res > best:\n",
    "                best = res\n",
    "                best_values = (k, alpha)\n",
    "    return best, best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcce58ca-17d1-4716-9a74-44ad09810aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6578333333333333, with values (5, 0.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "smoothing_paramters = list(range(5, 76, 5))\n",
    "alpha_values = list(x/100 for x in range(5, 101, 5))\n",
    "\n",
    "best, best_values = matrix_parameter_tuning(df_dev, smoothing_paramters, alpha_values)\n",
    "\n",
    "print(f\"Best: {best}, with values {best_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5efadcb-0f7e-4398-8701-1dfa29907664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6583214285714285, with values (6, 0.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "close_sp = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "close_alpha = [0.41, 0.42, 0.43, 0.44, 0.45, 0.56, 0.47, 0.48, 0.49]\n",
    "\n",
    "local_best, local_best_values = matrix_parameter_tuning(df_dev, close_sp, close_alpha)\n",
    "print(f\"Best: {local_best}, with values {local_best_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ef262b4-81b6-487a-9023-3ca3923d7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"hybrid\"] = df_dev.apply(\n",
    "    lambda x: reciprocal_rank_fusion(\n",
    "        x[\"bm25_topk\"],\n",
    "        x[\"reranked\"],\n",
    "        k=6,\n",
    "        alpha=0.43\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76aaf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bm25 = get_performance_mrr(df_dev, \"gold_paper\", \"bm25_topk\")\n",
    "results_granite = get_performance_mrr(df_dev, \"gold_paper\", \"retrieved\")\n",
    "results_reranked = get_performance_mrr(df_dev, \"gold_paper\", \"reranked\")\n",
    "results_hybrid = get_performance_mrr(df_dev, \"gold_paper\", \"hybrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d04b65b4-3eed-4f9c-99ba-0198ffb8fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results: {1: 0.5057142857142857, 5: 0.5522738095238094, 10: 0.557658163265306}\n",
      "Granite Results: {1: 0.5257142857142857, 5: 0.5813214285714287, 10: 0.5882225056689343}\n",
      "Reranked Results: {1: 0.5742857142857143, 5: 0.628904761904762, 10: 0.6347264739229024}\n",
      "Hybrid Results: {1: 0.605, 5: 0.6583214285714285, 10: 0.6583214285714285}\n"
     ]
    }
   ],
   "source": [
    "print(\"BM25 Results:\", results_bm25)\n",
    "print(\"Granite Results:\", results_granite)\n",
    "print(\"Reranked Results:\", results_reranked)\n",
    "print(\"Hybrid Results:\", results_hybrid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
