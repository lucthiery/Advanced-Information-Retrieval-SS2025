{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f24702",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "This closely follows Jonathan Katz' Hybrid Search blog post which can be found here: (https://jkatz05.com/post/postgres/hybrid-search-postgres-pgvector/)[https://jkatz05.com/post/postgres/hybrid-search-postgres-pgvector/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad9152e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import psycopg2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "model = SentenceTransformer('ibm-granite/granite-embedding-278m-multilingual', device='cuda')\n",
    "\n",
    "def embed_texts(texts, model, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        output = model.encode(batch, convert_to_tensor=True).cpu()\n",
    "        embeddings.extend(output)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7caf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77ba6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"air\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    port=\"5432\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a144d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs.json\", \"r\") as f:\n",
    "    paper_chunks = json.load(f)\n",
    "\n",
    "# Group chunks by paper ID\n",
    "paper_dict = {}\n",
    "for entry in paper_chunks:\n",
    "    uid = entry[\"cord_uid\"]\n",
    "    paper_dict.setdefault(uid, []).append(entry[\"text\"])\n",
    "\n",
    "df = pd.read_csv(\"../X_Data/subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"../X_Data/subtask4b_query_tweets_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9f403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23256f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    # Enable vector extension\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS embeddings;\")\n",
    "\n",
    "    # Create Table if it doesn't exist\n",
    "    cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS embeddings (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            paper_id TEXT NOT NULL,\n",
    "            paper_text TEXT NOT NULL,\n",
    "            embedding vector({model.get_sentence_embedding_dimension()}) NOT NULL\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b0d0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7718 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "HIP error: invalid device function\nHIP kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing AMD_SERIALIZE_KERNEL=3\nCompile with `TORCH_USE_HIP_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(texts)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Embed the text\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m paper_embeddings\u001b[38;5;241m.\u001b[39mappend((uid, text, embedding))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:685\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 685\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    687\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:758\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    757\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    444\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:915\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 915\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:100\u001b[0m, in \u001b[0;36mXLMRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Create the position ids from the input token ids. Any padded tokens remain padded.\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_position_ids_from_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1700\u001b[0m, in \u001b[0;36mcreate_position_ids_from_input_ids\u001b[0;34m(input_ids, padding_idx, past_key_values_length)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03mReplace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding symbols\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03mare ignored. This is modified from fairseq's `utils.make_positions`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03mReturns: torch.Tensor\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\u001b[39;00m\n\u001b[0;32m-> 1700\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m   1701\u001b[0m incremental_indices \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mcumsum(mask, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype_as(mask) \u001b[38;5;241m+\u001b[39m past_key_values_length) \u001b[38;5;241m*\u001b[39m mask\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m incremental_indices\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m+\u001b[39m padding_idx\n",
      "\u001b[0;31mRuntimeError\u001b[0m: HIP error: invalid device function\nHIP kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing AMD_SERIALIZE_KERNEL=3\nCompile with `TORCH_USE_HIP_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Get paper embeddings\n",
    "\n",
    "paper_embeddings = []\n",
    "for uid, texts in tqdm(paper_dict.items()):\n",
    "    # Join the text chunks into a single string\n",
    "    text = \" \".join(texts)\n",
    "    # Embed the text\n",
    "    embedding = model.encode(text)\n",
    "    paper_embeddings.append((uid, text, embedding))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0ca65f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"DELETE FROM embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "581657f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7718/7718 [00:12<00:00, 603.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Insert paper text and embeddings into the database\n",
    "with conn.cursor() as cursor:\n",
    "    for uid, text, embedding in tqdm(paper_embeddings):\n",
    "        # Convert the embedding to a list\n",
    "        embedding_list = embedding.tolist()\n",
    "        # Insert into the database\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO embeddings (paper_id, paper_text, embedding)\n",
    "            VALUES (%s, %s, %s)\n",
    "            \"\"\", (uid, text, embedding_list))\n",
    "    # HNSW index for faster similarity search\n",
    "   \n",
    "        \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b58b14d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the embeddings table: 7718\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM embeddings\n",
    "    \"\"\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"Total number of rows in the embeddings table: {count}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b883c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "                   CREATE INDEX IF NOT EXISTS paper_hnsw_idx ON embeddings USING hnsw(embedding vector_cosine_ops) WITH (M=16, ef_construction=200)\n",
    "                   \"\"\")\n",
    "    # GIN index for full-text search\n",
    "    cursor.execute(\"\"\"\n",
    "                   CREATE INDEX IF NOT EXISTS paper_ft_idx ON embeddings USING GIN (to_tsvector('english', paper_text))\n",
    "                   \"\"\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "709256e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:27<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_embeddings = embed_texts(dev_df[\"tweet_text\"].tolist(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7fe7be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search_query = \"\"\"\n",
    "WITH\n",
    "-- Vector search top 100\n",
    "vector_results AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    paper_id,\n",
    "    paper_text,\n",
    "    ROW_NUMBER() OVER (ORDER BY embedding <#> %(query_embedding)s::vector) AS vector_rank\n",
    "  FROM embeddings\n",
    "  ORDER BY embedding <#> %(query_embedding)s::vector\n",
    "  LIMIT 100\n",
    "),\n",
    "\n",
    "-- Full-text search top 100\n",
    "text_results AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    paper_id,\n",
    "    paper_text,\n",
    "    ROW_NUMBER() OVER (\n",
    "      ORDER BY ts_rank_cd(to_tsvector('english', paper_text), websearch_to_tsquery('english', %(query_text)s)) DESC\n",
    "    ) AS text_rank\n",
    "  FROM embeddings\n",
    "  WHERE websearch_to_tsquery('english', %(query_text)s) @@ to_tsvector('english', paper_text)\n",
    "  LIMIT 100\n",
    "),\n",
    "\n",
    "-- Combine results\n",
    "combined AS (\n",
    "  SELECT\n",
    "    COALESCE(v.id, t.id) AS id,\n",
    "    COALESCE(v.paper_id, t.paper_id) AS paper_id,\n",
    "    COALESCE(v.paper_text, t.paper_text) AS paper_text,\n",
    "    COALESCE(v.vector_rank, 1000) AS vector_rank,\n",
    "    COALESCE(t.text_rank, 1000) AS text_rank,\n",
    "    (1.0 / (60 + COALESCE(v.vector_rank, 1000)) +\n",
    "     1.0 / (60 + COALESCE(t.text_rank, 1000))) AS rrf_score\n",
    "  FROM vector_results v\n",
    "  FULL OUTER JOIN text_results t ON v.id = t.id\n",
    "),\n",
    "\n",
    "-- Choose the top chunk per paper\n",
    "ranked_chunks AS (\n",
    "  SELECT *,\n",
    "         ROW_NUMBER() OVER (PARTITION BY paper_id ORDER BY rrf_score DESC) AS per_paper_rank\n",
    "  FROM combined\n",
    ")\n",
    "\n",
    "-- Get top 5 unique papers\n",
    "SELECT paper_id, paper_text\n",
    "FROM ranked_chunks\n",
    "WHERE per_paper_rank = 1\n",
    "ORDER BY rrf_score DESC\n",
    "LIMIT 5;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbaa364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function when code errors in transaction\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"ROLLBACK;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2dc2b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:37, 37.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get results for first 5 tweets\n",
    "# Get the top 5 results for each tweet and put them in a list\n",
    "# with the tweet id, cord_uid (gold paper) and the retrieved paper ids\n",
    "all_results = []\n",
    "\n",
    "for i, (tweet_id, tweet_text, gold_paper) in tqdm(enumerate(zip(dev_df[\"post_id\"].tolist(), dev_df[\"tweet_text\"].tolist(), dev_df[\"cord_uid\"].tolist()))):\n",
    "    # Get the embedding for the tweet\n",
    "    tweet_embedding = tweet_embeddings[i].tolist()\n",
    "    \n",
    "    # Execute the hybrid search query\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(hybrid_search_query, {\n",
    "            'query_embedding': tweet_embedding,\n",
    "            'query_text': tweet_text\n",
    "        })\n",
    "        results = cursor.fetchall()\n",
    "        # Add the results to the list\n",
    "        all_results.append({\n",
    "            \"tweet_id\": tweet_id,\n",
    "            \"gold_paper\": gold_paper,\n",
    "            \"retrieved_papers\": results\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d49086ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 1400\n",
      "MRR5 803.4500000000006\n",
      "MRR5 0.5738928571428575\n",
      "MRR@5: 0.5739\n"
     ]
    }
   ],
   "source": [
    "# Calculate MRR5\n",
    "\n",
    "def calculate_mrr5(results):\n",
    "    mrr5 = 0.0\n",
    "    for result in results:\n",
    "        gold_paper = result[\"gold_paper\"]\n",
    "        retrieved_papers = [paper[0] for paper in result[\"retrieved_papers\"]]\n",
    "        # Find the rank of the gold paper\n",
    "        if gold_paper in retrieved_papers:\n",
    "            rank = retrieved_papers.index(gold_paper) + 1\n",
    "            mrr5 += 1.0 / rank\n",
    "    print(\"Results\", len(results))\n",
    "    print(\"MRR5\", mrr5)\n",
    "\n",
    "    mrr5 /= len(results)\n",
    "    print(\"MRR5\", mrr5)\n",
    "    return mrr5\n",
    "\n",
    "mrr5 = calculate_mrr5(all_results)\n",
    "\n",
    "print(f\"MRR@5: {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "64330747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:35, 39.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get top 5 results from vector search\n",
    "\n",
    "vector_results = []\n",
    "\n",
    "for i, (tweet_id, tweet_text, gold_paper) in tqdm(enumerate(zip(dev_df[\"post_id\"].tolist(), dev_df[\"tweet_text\"].tolist(), dev_df[\"cord_uid\"].tolist()))):\n",
    "    # Get the embedding for the tweet\n",
    "    tweet_embedding = tweet_embeddings[i].tolist()\n",
    "    \n",
    "    # Execute the vector search query\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "        WITH paper_rank AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    paper_id,\n",
    "    paper_text,\n",
    "    ROW_NUMBER() OVER (ORDER BY embedding <#> %(query_embedding)s::vector) AS vector_rank\n",
    "  FROM embeddings\n",
    "  ORDER BY embedding <#> %(query_embedding)s::vector\n",
    "  )\n",
    "           \n",
    "            SELECT paper_id, paper_text\n",
    "            FROM paper_rank\n",
    "            WHERE vector_rank = 1\n",
    "            LIMIT 5\n",
    "        \"\"\", {\"query_embedding\": tweet_embedding})\n",
    "        results = cursor.fetchall()\n",
    "        # Add the results to the list\n",
    "        vector_results.append({\n",
    "            \"tweet_id\": tweet_id,\n",
    "            \"gold_paper\": gold_paper,\n",
    "            \"retrieved_papers\": results\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "14a020fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 1400\n",
      "MRR5 718.0\n",
      "MRR5 0.5128571428571429\n",
      "MRR@5 (Vector Search): 0.5129\n"
     ]
    }
   ],
   "source": [
    "mrr5 = calculate_mrr5(vector_results)\n",
    "\n",
    "print(f\"MRR@5 (Vector Search): {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "73251313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:01, 1068.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get top 5 results from text search\n",
    "text_results = []\n",
    "\n",
    "for i, (tweet_id, tweet_text, gold_paper) in tqdm(enumerate(zip(dev_df[\"post_id\"].tolist(), dev_df[\"tweet_text\"].tolist(), dev_df[\"cord_uid\"].tolist()))):\n",
    "    # Get the embedding for the tweet\n",
    "    tweet_embedding = tweet_embeddings[i].tolist()\n",
    "    \n",
    "    # Execute the text search query\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "        WITH paper_rank AS (\n",
    "  SELECT\n",
    "    id,\n",
    "    paper_id,\n",
    "    paper_text,\n",
    "    ROW_NUMBER() OVER (\n",
    "      ORDER BY ts_rank_cd(to_tsvector('english', paper_text), websearch_to_tsquery('english', %(query_text)s)) DESC\n",
    "    ) AS text_rank\n",
    "  FROM embeddings\n",
    "  WHERE websearch_to_tsquery('english', %(query_text)s) @@ to_tsvector('english', paper_text)\n",
    "  )\n",
    "           \n",
    "            SELECT paper_id, paper_text\n",
    "            FROM paper_rank\n",
    "            WHERE text_rank = 1\n",
    "            LIMIT 5\n",
    "        \"\"\", {\"query_text\": tweet_text})\n",
    "        results = cursor.fetchall()\n",
    "        # Add the results to the list\n",
    "        text_results.append({\n",
    "            \"tweet_id\": tweet_id,\n",
    "            \"gold_paper\": gold_paper,\n",
    "            \"retrieved_papers\": results\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0efe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a67f1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 1400\n",
      "MRR5 33.0\n",
      "MRR5 0.023571428571428573\n",
      "MRR@5 (Text Search): 0.0236\n"
     ]
    }
   ],
   "source": [
    "mrr5 = calculate_mrr5(text_results)\n",
    "print(f\"MRR@5 (Text Search): {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7cdb244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tweet_id': 16, 'gold_paper': '3qvh482o', 'retrieved_papers': [('hg3xpej0', \"BACKGROUND: There is growing concern about possible cognitive consequences of COVID-19, with reports of ‘Long COVID’ symptoms persisting into the chronic phase and case studies revealing neurological problems in severely affected patients. However, there is little information regarding the nature and broader prevalence of cognitive problems post-infection or across the full spread of disease severity. METHODS: We sought to confirm whether there was an association between cross-sectional cognitive performance data from 81,337 participants who between January and December 2020 undertook a clinically validated web-optimized assessment as part of the Great British Intelligence Test, and questionnaire items capturing self-report of suspected and confirmed COVID-19 infection and respiratory symptoms. FINDINGS: People who had recovered from COVID-19, including those no longer reporting symptoms, exhibited significant cognitive deficits versus controls when controlling for age, gender, education level, income, racial-ethnic group, pre-existing medical disorders, tiredness, depression and anxiety. The deficits were of substantial effect size for people who had been hospitalised (N = 192), but also for non-hospitalised cases who had biological confirmation of COVID-19 infection (N = 326). Analysing markers of premorbid intelligence did not support these differences being present prior to infection. Finer grained analysis of performance across sub-tests supported the hypothesis that COVID-19 has a multi-domain impact on human cognition. INTERPRETATION: Interpretation. These results accord with reports of ‘Long Covid’ cognitive symptoms that persist into the early-chronic phase. They should act as a clarion call for further research with longitudinal and neuroimaging cohorts to plot recovery trajectories and identify the biological basis of cognitive deficits in SARS-COV-2 survivors. FUNDING: Funding. AH is supported by the UK Dementia Research Institute Care Research and Technology Centre and Biomedical Research Centre at Imperial College London. WT is supported by the EPSRC Centre for Doctoral Training in Neurotechnology. SRC is funded by a Wellcome Trust Clinical Fellowship 110,049/Z/15/Z. JMB is supported by Medical Research Council (MR/N013700/1). MAM, SCRW and PJH are, in part, supported by the National Institute for Health Research (NIHR) Biomedical Research Centre at South London and Maudsley NHS Foundation Trust and King's College London Cognitive deficits in people who have recovered from COVID-19\"), ('8t2tic9n', 'INTRODUCTION: We conducted a systematic review and meta‐analysis of the cognitive effects of coronavirus disease 2019 (COVID‐19) in adults with no prior history of cognitive impairment. METHODS: Searches in Medline/Web of Science/Embase from January 1, 2020, to December 13, 2021, were performed following Preferred Reporting Items for Systematic Reviews and Meta‐Analyses (PRISMA) guidelines. A meta‐analysis of the Montreal Cognitive Assessment (MoCA) total score comparing recovered COVID‐19 and healthy controls was performed. RESULTS: Oof 6202 articles, 27 studies with 2049 individuals were included (mean age = 56.05 years, evaluation time ranged from the acute phase to 7 months post‐infection). Impairment in executive functions, attention, and memory were found in post‐COVID‐19 patients. The meta‐analysis was performed with a subgroup of 290 individuals and showed a difference in MoCA score between post‐COVID‐19 patients versus controls (mean difference = −0.94, 95% confidence interval [CI] −1.59, −0.29; P = .0049). DISCUSSION: Patients recovered from COVID‐19 have lower general cognition compared to healthy controls up to 7 months post‐infection. Changes in cognitive functioning after COVID‐19: A systematic review and meta‐analysis'), ('trrg1mnw', \"BACKGROUND: A significant number of patients with COVID-19 experience prolonged symptoms, known as Long COVID. Few systematic studies have investigated this population, particularly in outpatient settings. Hence, relatively little is known about symptom makeup and severity, expected clinical course, impact on daily functioning, and return to baseline health. METHODS: We conducted an online survey of people with suspected and confirmed COVID-19, distributed via COVID-19 support groups (e.g. Body Politic, Long COVID Support Group, Long Haul COVID Fighters) and social media (e.g. Twitter, Facebook). Data were collected from September 6, 2020 to November 25, 2020. We analyzed responses from 3762 participants with confirmed (diagnostic/antibody positive; 1020) or suspected (diagnostic/antibody negative or untested; 2742) COVID-19, from 56 countries, with illness lasting over 28 days and onset prior to June 2020. We estimated the prevalence of 203 symptoms in 10 organ systems and traced 66 symptoms over seven months. We measured the impact on life, work, and return to baseline health. FINDINGS: For the majority of respondents (>91%), the time to recovery exceeded 35 weeks. During their illness, participants experienced an average of 55.9+/- 25.5 (mean+/-STD) symptoms, across an average of 9.1 organ systems. The most frequent symptoms after month 6 were fatigue, post-exertional malaise, and cognitive dysfunction. Symptoms varied in their prevalence over time, and we identified three symptom clusters, each with a characteristic temporal profile. 85.9% of participants (95% CI, 84.8% to 87.0%) experienced relapses, primarily triggered by exercise, physical or mental activity, and stress. 86.7% (85.6% to 92.5%) of unrecovered respondents were experiencing fatigue at the time of survey, compared to 44.7% (38.5% to 50.5%) of recovered respondents. 1700 respondents (45.2%) required a reduced work schedule compared to pre-illness, and an additional 839 (22.3%) were not working at the time of survey due to illness. Cognitive dysfunction or memory issues were common across all age groups (~88%). Except for loss of smell and taste, the prevalence and trajectory of all symptoms were similar between groups with confirmed and suspected COVID-19. INTERPRETATION: Patients with Long COVID report prolonged, multisystem involvement and significant disability. By seven months, many patients have not yet recovered (mainly from systemic and neurological/cognitive symptoms), have not returned to previous levels of work, and continue to experience significant symptom burden. FUNDING: All authors contributed to this work in a voluntary capacity. The cost of survey hosting (on Qualtrics) and publication fee was covered by AA's research grant (Wellcome Trust/Gatsby Charity via Sainsbury Wellcome center, UCL). Characterizing long COVID in an international cohort: 7 months of symptoms and their impact\"), ('hsm75cww', 'Many people are not recovering for months after being infected with SARS-CoV-2. Long Covid has emerged as a major public health concern that needs defining, quantifying, and describing. We aimed to explore the initial and ongoing symptoms of Long Covid following SARS-CoV-2 infection and describe its impact on daily life in people who were not admitted to hospital during the first two weeks of the illness. We co-produced a survey with people living with Long Covid. We collected the data through an online survey using convenience non-probability sampling, with the survey posted both specifically on Long Covid support groups and generally on social media. The criteria for inclusion were adults with lab-confirmed (PCR or antibody) or suspected COVID-19 managed in the community (non-hospitalised) in the first two weeks of illness. We used agglomerative hierarchical clustering to identify specific symptom clusters, and their demographic and functional correlates. We analysed data from 2550 participants with a median duration of illness of 7.7 months (interquartile range (IQR) 7.4-8.0). The mean age was 46.5 years (standard deviation 11 years) with 82.8% females and 79.9% of participants based in the UK. 89.5% described their health as good, very good or excellent before COVID-19. The most common initial symptoms that persisted were exhaustion, chest pressure/tightness, shortness of breath and headache. Cough, fever, and chills were common initial symptoms that became less prevalent later in the illness, whereas cognitive dysfunction and palpitations became more prevalent later in the illness. 26.5% reported lab-confirmation of infection. The biggest difference in ongoing symptoms between those who reported testing positive and those who did not was loss of smell/taste. Ongoing symptoms affected at least 3 organ systems in 83.5% of participants. Most participants described fluctuating (57.7%) or relapsing symptoms (17.6%). Physical activity, stress and sleep disturbance commonly triggered symptoms. A third (32%) reported they were unable to live alone without any assistance at six weeks from start of illness. 16.9% reported being unable to work solely due to COVID-19 illness. 66.4% reported taking time off sick (median of 60 days, IQR 20, 129). 37.0% reported loss of income due to illness, and 64.4% said they were unable to perform usual activities/duties. Acute systems clustered broadly into two groups: a majority cluster (n=2235, 88%) with cardiopulmonary predominant symptoms, and a minority cluster (n=305, 12%) with multisystem symptoms. Similarly, ongoing symptoms broadly clustered in two groups; a majority cluster (n=2243, 88.8%) exhibiting mainly cardiopulmonary, cognitive symptoms and exhaustion, and a minority cluster (n=283, 11.2%) exhibited more multisystem symptoms. Belonging to the more severe multisystem cluster was associated with more severe functional impact, lower income, younger age, being female, worse baseline health, and inadequate rest in the first two weeks of the illness, with no major differences in the cluster patterns when restricting analysis to the lab-confirmed subgroup. This is an exploratory survey of Long Covid characteristics. Whilst it is important to acknowledge that it is a non-representative population sample, it highlights the heterogeneity of persistent symptoms, and the significant functional impact of prolonged illness following confirmed or suspected SARS-CoV-2 infection. To study prevalence, predictors and prognosis, research is needed in a representative population sample using standardised case definitions (to include those not lab-confirmed in the first pandemic wave). Characteristics of Long Covid: findings from a social media surve'), ('3qvh482o', 'This cross-sectional study examines rates of cognitive impairment among patients who survived COVID-19 and whether the care setting was associated with cognitive impairment rates. Assessment of Cognitive Function in Patients After COVID-19 Infection')]}, {'tweet_id': 69, 'gold_paper': 'r58aohnu', 'retrieved_papers': [('r58aohnu', 'On May 12, 2020 (day 0), a hair stylist at salon A in Springfield, Missouri (stylist A), developed respiratory symptoms and continued working with clients until day 8, when the stylist received a positive test result for SARS-CoV-2, the virus that causes coronavirus disease 2019 (COVID-19). A second hair stylist (stylist B), who had been exposed to stylist A, developed respiratory symptoms on May 15, 2020 (day 3), and worked with clients at salon A until day 8 before seeking testing for SARS-CoV-2, which returned a positive result on day 10. A total of 139 clients were directly serviced by stylists A and B from the time they developed symptoms until they took leave from work. Stylists A and B and the 139 clients followed the City of Springfield ordinance* and salon A policy recommending the use of face coverings (i.e., surgical masks, N95 respirators,† or cloth face coverings) for both stylists and clients during their interactions. Other stylists at salon A who worked closely with stylists A and B were identified, quarantined, and monitored daily for 14 days after their last exposure to stylists A or B. None of these stylists reported COVID-19 symptoms. After stylist B received a positive test result on day 10, salon A closed for 3 days to disinfect frequently touched and contaminated areas. After public health contact tracings and 2 weeks of follow-up, no COVID-19 symptoms were identified among the 139 exposed clients or their secondary contacts. The citywide ordinance and company policy might have played a role in preventing spread of SARS-CoV-2 during these exposures. These findings support the role of source control in preventing transmission and can inform the development of public health policy during the COVID-19 pandemic. As stay-at-home orders are lifted, professional and social interactions in the community will present more opportunities for spread of SARS-CoV-2. Broader implementation of masking policies could mitigate the spread of infection in the general population. Absence of Apparent Transmission of SARS-CoV-2 from Two Stylists After Exposure at a Hair Salon with a Universal Face Covering Policy - Springfield, Missouri, May 2020.'), ('zd8c1no7', 'BACKGROUND: On 07/02/2020, French Health authorities were informed of a confirmed case of SARS-CoV-2 coronavirus in an Englishman infected in Singapore who had recently stayed in a chalet in the French Alps. We conducted an investigation to identify secondary cases and interrupt transmission. METHODS: We defined as a confirmed case a person linked to the chalet with a positive RT-PCR sample for SARS-CoV-2. RESULTS: The index case stayed 4 days in the chalet with 10 English tourists and a family of 5 French residents; SARS-CoV-2 was detected in 5 individuals in France, 6 in England (including the index case), and 1 in Spain (overall attack rate in the chalet: 75%). One pediatric case, with picornavirus and influenza A coinfection, visited 3 different schools while symptomatic. One case was asymptomatic, with similar viral load as that of a symptomatic case. Seven days after the first cases were diagnosed, one tertiary case was detected in a symptomatic patient with a positive endotracheal aspirate; all previous and concurrent nasopharyngeal specimens were negative. Additionally, 172 contacts were monitored, including 73 tested negative for SARS-CoV-2. CONCLUSIONS: The occurrence in this cluster of one asymptomatic case with similar viral load as a symptomatic patient, suggests transmission potential of asymptomatic individuals. The fact that an infected child did not transmit the disease despite close interactions within schools suggests potential different transmission dynamics in children. Finally, the dissociation between upper and lower respiratory tract results underscores the need for close monitoring of the clinical evolution of suspect Covid-19 cases. Cluster of coronavirus disease 2019 (Covid-19) in the French Alps, 2020'), ('ximw03ej', \"BACKGROUND: Observational evidence suggests that mask wearing mitigates transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It is uncertain if this observed association arises through protection of uninfected wearers (protective effect), via reduced transmission from infected mask wearers (source control), or both. OBJECTIVE: To assess whether recommending surgical mask use outside the home reduces wearers' risk for SARS-CoV-2 infection in a setting where masks were uncommon and not among recommended public health measures. DESIGN: Randomized controlled trial (DANMASK-19 [Danish Study to Assess Face Masks for the Protection Against COVID-19 Infection]). (ClinicalTrials.gov: NCT04337541) SETTING: Denmark, April and May 2020. PARTICIPANTS: Adults spending more than 3 hours per day outside the home without occupational mask use. INTERVENTION: Encouragement to follow social distancing measures for coronavirus disease 2019, plus either no mask recommendation or a recommendation to wear a mask when outside the home among other persons together with a supply of 50 surgical masks and instructions for proper use. MEASUREMENTS: The primary outcome was SARS-CoV-2 infection in the mask wearer at 1 month by antibody testing, polymerase chain reaction (PCR), or hospital diagnosis. The secondary outcome was PCR positivity for other respiratory viruses. RESULTS: A total of 3030 participants were randomly assigned to the recommendation to wear masks, and 2994 were assigned to control; 4862 completed the study. Infection with SARS-CoV-2 occurred in 42 participants recommended masks (1.8%) and 53 control participants (2.1%). The between-group difference was −0.3 percentage point (95% CI, −1.2 to 0.4 percentage point; P = 0.38) (odds ratio, 0.82 [CI, 0.54 to 1.23]; P = 0.33). Multiple imputation accounting for loss to follow-up yielded similar results. Although the difference observed was not statistically significant, the 95% CIs are compatible with a 46% reduction to a 23% increase in infection. LIMITATION: Inconclusive results, missing data, variable adherence, patient-reported findings on home tests, no blinding, and no assessment of whether masks could decrease disease transmission from mask wearers to others. CONCLUSION: The recommendation to wear surgical masks to supplement other public health measures did not reduce the SARS-CoV-2 infection rate among wearers by more than 50% in a community with modest infection rates, some degree of social distancing, and uncommon general mask use. The data were compatible with lesser degrees of self-protection. PRIMARY FUNDING SOURCE: The Salling Foundations. Effectiveness of Adding a Mask Recommendation to Other Public Health Measures to Prevent SARS-CoV-2 Infection in Danish Mask Wearers: A Randomized Controlled Trial\"), ('xtmn1n0r', 'INTRODUCTION: The original use of face masks was to help protect surgical wounds from staff-generated nasal and oral bacteria. Currently governments across the world have instituted the mandatory use of masks and other face coverings so that face masks now find much broader usage in situations where close contact of people is frequent and inevitable, particularly inside public transport facilities, shopping malls and workplaces in response to the COVID-19. OBJECTIVE: We conducted a rapid review to investigate the impact face mask use has had in controlling transmission of respiratory viral infections. METHOD: A rapid review was conducted in line with Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidance. Five electronic databases (CINAHL, Embase, Medline, PsycINFO and Global Health) were searched from database inception to date, using pre-defined search terms. We included all studies of any design and used descriptive analysis to report summary statistics of search results. Data were extracted including sample characteristics, study design, respiratory virus being controlled, type of face masks used and their effectiveness. RESULTS: 58 out of 84 studies met the inclusion criteria, of which 13 were classified as systematic reviews and 45 were quantitative studies (comprising randomised controlled trials, retrospective cohort studies, case control, cross-sectional, surveys, observational and descriptive studies). N = 27 studies were conducted amongst healthcare workers wearing face masks, n = 19 studies among the general population, n = 9 studies among healthcare workers the general population and patients wearing masks, and n = 3 among only patients. Face masks use have shown a great potential for preventing respiratory virus transmission including COVID-19. CONCLUSION: Regardless of the type, setting, or who wears the face mask, it serves primarily a dual preventive purpose; protecting oneself from getting viral infection and protecting others. Therefore, if everyone wears a face mask in public, it offers a double barrier against COVID-19 transmission. A rapid review of the use of face mask in preventing the spread of COVID-19'), ('vkf5njfz', 'BACKGROUND: Scarce data are available on what variables affect the risk of transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the development of symptomatic COVID-19, and, particularly, the relationship with viral load. We aimed to analyse data from linked index cases of COVID-19 and their contacts to explore factors associated with transmission of SARS-CoV-2. METHODS: In this cohort study, patients were recruited as part of a randomised controlled trial done between March 17 and April 28, 2020, that aimed to assess if hydroxychloroquine reduced transmission of SARS-CoV-2. Patients with COVID-19 and their contacts were identified by use of the electronic registry of the Epidemiological Surveillance Emergency Service of Catalonia (Spain). Patients with COVID-19 included in our analysis were aged 18 years or older, not hospitalised, had quantitative PCR results available at baseline, had mild symptom onset within 5 days before enrolment, and had no reported symptoms of SARS-CoV-2 infections in their accommodation or workplace within the 14 days before enrolment. Contacts included were adults with a recent history of exposure and absence of COVID-19-like symptoms within the 7 days preceding enrolment. Viral load of contacts, measured by quantitative PCR from a nasopharyngeal swab, was assessed at enrolment, at day 14, and whenever the participant reported COVID-19-like symptoms. We assessed risk of transmission and developing symptomatic disease and incubation dynamics using regression analysis. We assessed the relationship of viral load and characteristics of cases (age, sex, number of days from reported symptom onset, and presence or absence of fever, cough, dyspnoea, rhinitis, and anosmia) and associations between risk of transmission and characteristics of the index case and contacts. FINDINGS: We identified 314 patients with COVID-19, with 282 (90%) having at least one contact (753 contacts in total), resulting in 282 clusters. 90 (32%) of 282 clusters had at least one transmission event. The secondary attack rate was 17% (125 of 753 contacts), with a variation from 12% when the index case had a viral load lower than 1 × 10(6) copies per mL to 24% when the index case had a viral load of 1 × 10(10) copies per mL or higher (adjusted odds ratio per log(10) increase in viral load 1·3, 95% CI 1·1–1·5). Increased risk of transmission was also associated with household contact (3·0, 1·59–5·65) and age of the contact (per year: 1·02, 1·01–1·04). 449 contacts had a positive PCR result at baseline. 28 (6%) of 449 contacts had symptoms at the first visit. Of 421 contacts who were asymptomatic at the first visit, 181 (43%) developed symptomatic COVID-19, with a variation from approximately 38% in contacts with an initial viral load lower than 1 × 10(7) copies per mL to greater than 66% for those with an initial viral load of 1 × 10(10) copies per mL or higher (hazard ratio per log(10) increase in viral load 1·12, 95% CI 1·05–1·20; p=0·0006). Time to onset of symptomatic disease decreased from a median of 7 days (IQR 5–10) for individuals with an initial viral load lower than 1 × 10(7) copies per mL to 6 days (4–8) for those with an initial viral load between 1 × 10(7) and 1 × 10(9) copies per mL, and 5 days (3–8) for those with an initial viral load higher than 1 × 10(9) copies per mL. INTERPRETATION: In our study, the viral load of index cases was a leading driver of SARS-CoV-2 transmission. The risk of symptomatic COVID-19 was strongly associated with the viral load of contacts at baseline and shortened the incubation time of COVID-19 in a dose-dependent manner. FUNDING: YoMeCorono, Generalitat de Catalunya. TRANSLATIONS: For the Catalan translation of the abstract see Supplementary Materials section. Transmission of COVID-19 in 282 clusters in Catalonia, Spain: a cohort study')]}, {'tweet_id': 73, 'gold_paper': 'sts48u9i', 'retrieved_papers': [('9x1d1kp1', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has rapidly spread within the human population. Although SARS-CoV-2 is a novel coronavirus, most humans had been previously exposed to other antigenically distinct common seasonal human coronaviruses (hCoVs) before the COVID-19 pandemic. Here, we quantified levels of SARS-CoV-2-reactive antibodies and hCoV-reactive antibodies in serum samples collected from 204 humans before the COVID-19 pandemic. We then quantified pre-pandemic antibody levels in serum from a separate cohort of 252 individuals who became PCR-confirmed infected with SARS-CoV-2. Finally, we longitudinally measured hCoV and SARS-CoV-2 antibodies in the serum of hospitalized COVID-19 patients. Our studies indicate that most individuals possessed hCoV-reactive antibodies before the COVID-19 pandemic. We determined that ~23% of these individuals possessed non-neutralizing antibodies that cross-reacted with SARS-CoV-2 spike and nucleocapsid proteins. These antibodies were not associated with protection against SARS-CoV-2 infections or hospitalizations, but paradoxically these hCoV cross-reactive antibodies were boosted upon SARS-CoV-2 infection. Seasonal human coronavirus antibodies are boosted upon SARS-CoV-2 infection but not associated with protection'), ('sts48u9i', 'BACKGROUND: Although the mechanisms of adaptive immunity to pandemic severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) are still unknown, the immune response to the widespread endemic coronaviruses HKU1, 229E, NL63, and OC43 provide a useful reference for understanding repeat infection risk. METHODS: Here we used data from proactive sampling carried out in New York City from fall 2016 to spring 2018. We combined weekly nasal swab collection with self-reports of respiratory symptoms from 191 participants to investigate the profile of recurring infections with endemic coronaviruses. RESULTS: During the study, 12 individuals tested positive multiple times for the same coronavirus. We found no significant difference between the probability of testing positive at least once and the probability of a recurrence for the betacoronaviruses HKU1 and OC43 at 34 weeks after enrollment/first infection. We also found no significant association between repeat infections and symptom severity, but found strong association between symptom severity and belonging to the same family. CONCLUSIONS: This study provides evidence that reinfections with the same endemic coronavirus are not atypical in a time window shorter than 1 year and that the genetic basis of innate immune response may be a greater determinant of infection severity than immune memory acquired after a previous infection. Direct Observation of Repeated Infections With Endemic Coronaviruses'), ('ar3yoglq', '[Image: see text] Mucins are a diverse and heterogeneous family of glycoproteins that comprise the bulk of mucus and the epithelial glycocalyx. Mucins are intimately involved in viral transmission. Mucin and virus laden particles can be expelled from the mouth and nose to later infect others. Viruses must also penetrate the mucus layer before cell entry and replication. The role of mucins and their molecular structure have not been well-characterized in coronavirus transmission studies. Laboratory studies predicting high rates of fomite transmission have not translated to real-world infections, and mucins may be one culprit. Here, we probed both surface and direct contact transmission scenarios for their dependence on mucins and their structure. We utilized disease-causing, bovine-derived, human coronavirus OC43. We found that bovine mucins could inhibit the infection of live cells in a concentration- and glycan-dependent manner. The effects were observed in both mock fomite and direct contact transmission experiments and were not dependent upon surface material or time-on-surface. However, the effects were abrogated by removal of the glycans or in a cross-species infection scenario where bovine mucin could not inhibit the infection of a murine coronavirus. Together, our data indicate that the mucin molecular structure plays a complex and important role in host defense. Mucins Inhibit Coronavirus Infection in a Glycan-Dependent Manner'), ('0phcscz8', 'Background: Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a global pandemic. The percentage of infected individuals who seroconvert is still an open question. In addition, it has been shown in some individuals that viral genome can still be detected at considerable time post symptom resolution. Here we investigated both seroconversion and PCR-positivity in a large cohort of convalescent serum donors in New York City. Methods: Individuals with confirmed or suspected SARS-CoV-2 infection were screened via PCR for presence of viral genome and via enzyme-linked immunosorbent assay for presence of anti SARS-CoV-2 spike antibodies. Results: All but three confirmed SARS-CoV-2 patients seroconverted to the SARS-CoV-2 spike while only 37.4% of suspected SARS-CoV-2 patients seroconverted. PCR-positivity was detected up to 28 days from symptom resolution. Conclusions: Here we show that the vast majority of confirmed COVID19 patients seroconvert, potentially providing immunity to reinfection. We also report that in a large proportion of individuals, viral genome can be detected via PCR in the upper respiratory tract for weeks post symptom resolution, but it is unclear if this signal represents infectious virus. Humoral immune response and prolonged PCR positivity in a cohort of 1343 SARS-CoV 2 patients in the New York City region'), ('qkg8fwbp', 'A key unsolved question in the current coronavirus disease 2019 (COVID-19) pandemic is the duration of acquired immunity. Insights from infections with the four seasonal human coronaviruses might reveal common characteristics applicable to all human coronaviruses. We monitored healthy individuals for more than 35 years and determined that reinfection with the same seasonal coronavirus occurred frequently at 12 months after infection. Seasonal coronavirus protective immunity is short-lasting.')]}, {'tweet_id': 93, 'gold_paper': '3sr2exq9', 'retrieved_papers': [('3sr2exq9', 'OBJECTIVE: The study objective was to compare gut microbiome diversity and composition in SARS-CoV-2 PCR-positive patients whose symptoms ranged from asymptomatic to severe versus PCR-negative exposed controls. DESIGN: Using a cross-sectional design, we performed shotgun next-generation sequencing on stool samples to evaluate gut microbiome composition and diversity in both patients with SARS-CoV-2 PCR-confirmed infections, which had presented to Ventura Clinical Trials for care from March 2020 through October 2021 and SARS-CoV-2 PCR-negative exposed controls. Patients were classified as being asymptomatic or having mild, moderate or severe symptoms based on National Institute of Health criteria. Exposed controls were individuals with prolonged or repeated close contact with patients with SARS-CoV-2 infection or their samples, for example, household members of patients or frontline healthcare workers. Microbiome diversity and composition were compared between patients and exposed controls at all taxonomic levels. RESULTS: Compared with controls (n=20), severely symptomatic SARS-CoV-2-infected patients (n=28) had significantly less bacterial diversity (Shannon Index, p=0.0499; Simpson Index, p=0.0581), and positive patients overall had lower relative abundances of Bifidobacterium (p<0.0001), Faecalibacterium (p=0.0077) and Roseburium (p=0.0327), while having increased Bacteroides (p=0.0075). Interestingly, there was an inverse association between disease severity and abundance of the same bacteria. CONCLUSION: We hypothesise that low bacterial diversity and depletion of Bifidobacterium genera either before or after infection led to reduced proimmune function, thereby allowing SARS-CoV-2 infection to become symptomatic. This particular dysbiosis pattern may be a susceptibility marker for symptomatic severity from SARS-CoV-2 infection and may be amenable to preinfection, intrainfection or postinfection intervention. TRIAL REGISTRATION NUMBER: NCT04031469 (PCR−) and 04359836 (PCR+). Lost microbes of COVID-19: Bifidobacterium, Faecalibacterium depletion and decreased microbiome diversity associated with SARS-CoV-2 infection severity'), ('k0f4cwig', 'OBJECTIVE: Although COVID-19 is primarily a respiratory illness, there is mounting evidence suggesting that the GI tract is involved in this disease. We investigated whether the gut microbiome is linked to disease severity in patients with COVID-19, and whether perturbations in microbiome composition, if any, resolve with clearance of the SARS-CoV-2 virus. METHODS: In this two-hospital cohort study, we obtained blood, stool and patient records from 100 patients with laboratory-confirmed SARS-CoV-2 infection. Serial stool samples were collected from 27 of the 100 patients up to 30 days after clearance of SARS-CoV-2. Gut microbiome compositions were characterised by shotgun sequencing total DNA extracted from stools. Concentrations of inflammatory cytokines and blood markers were measured from plasma. RESULTS: Gut microbiome composition was significantly altered in patients with COVID-19 compared with non-COVID-19 individuals irrespective of whether patients had received medication (p<0.01). Several gut commensals with known immunomodulatory potential such as Faecalibacterium prausnitzii, Eubacterium rectale and bifidobacteria were underrepresented in patients and remained low in samples collected up to 30 days after disease resolution. Moreover, this perturbed composition exhibited stratification with disease severity concordant with elevated concentrations of inflammatory cytokines and blood markers such as C reactive protein, lactate dehydrogenase, aspartate aminotransferase and gamma-glutamyl transferase. CONCLUSION: Associations between gut microbiota composition, levels of cytokines and inflammatory markers in patients with COVID-19 suggest that the gut microbiome is involved in the magnitude of COVID-19 severity possibly via modulating host immune responses. Furthermore, the gut microbiota dysbiosis after disease resolution could contribute to persistent symptoms, highlighting a need to understand how gut microorganisms are involved in inflammation and COVID-19. Gut microbiota composition reflects disease severity and dysfunctional immune responses in patients with COVID-19'), ('0t5n87u6', 'There is a significant difference between COVID 19 associated mortality between different countries. Generally the number of deaths per million population are higher in the developed countries despite better health care efficiency, drinking water quality and expected healthy life span (HALE) at the time of birth. Developing and underdeveloped countries on the other hand have lower mortality even with higher rural and slum populations along with incidence of diarrhea because of lack of sanitation. We analyzed data from 122 countries out of which 80 were high or upper middle income and 42 were low or low middle income countries. There was statistically significant positive correlation between COVID 19 deaths /million population and water current score, health efficiency, and HALE. Statistically significant negative correlation was observed with % rural population and fraction of diarrhea because of inadequate sanitation for all ages. Moreover analysis of 51 countries showed that there is significant negative correlation between COVID 19 deaths /million population and proportion of total population living in slums. We propose that high microbial exposure particularly gram negative bacteria can possibly induce interferon type I which might have a protective effect against COVID 19 since the countries with less mortality also tend to have lack of sanitation and high incidence of attendant diseases. So, far none of the predictive models have taken into account immune status of populations engendered by environmental microbial exposure or microbiome. There might be a need to look at dynamics of COVID 19 pandemic using immune perspective. The approach can potentially inform better policies including interventions. COVID 19 mortality: Probable role of microbiome to explain disparity'), ('sv48gjkk', 'BACKGROUND: Long-term complications after COVID-19 are common, but the potential cause for persistent symptoms after viral clearance remains unclear. OBJECTIVE: To investigate whether gut microbiome composition is linked to post-acute COVID-19 syndrome (PACS), defined as at least one persistent symptom 4 weeks after clearance of the SARS-CoV-2 virus. METHODS: We conducted a prospective study of 106 patients with a spectrum of COVID-19 severity followed up from admission to 6 months and 68 non-COVID-19 controls. We analysed serial faecal microbiome of 258 samples using shotgun metagenomic sequencing, and correlated the results with persistent symptoms at 6 months. RESULTS: At 6 months, 76% of patients had PACS and the most common symptoms were fatigue, poor memory and hair loss. Gut microbiota composition at admission was associated with occurrence of PACS. Patients without PACS showed recovered gut microbiome profile at 6 months comparable to that of non-COVID-19 controls. Gut microbiome of patients with PACS were characterised by higher levels of Ruminococcus gnavus, Bacteroides vulgatus and lower levels of Faecalibacterium prausnitzii. Persistent respiratory symptoms were correlated with opportunistic gut pathogens, and neuropsychiatric symptoms and fatigue were correlated with nosocomial gut pathogens, including Clostridium innocuum and Actinomyces naeslundii (all p<0.05). Butyrate-producing bacteria, including Bifidobacterium pseudocatenulatum and Faecalibacterium prausnitzii showed the largest inverse correlations with PACS at 6 months. CONCLUSION: These findings provided observational evidence of compositional alterations of gut microbiome in patients with long-term complications of COVID-19. Further studies should investigate whether microbiota modulation can facilitate timely recovery from post-acute COVID-19 syndrome. Gut microbiota dynamics in a prospective cohort of patients with post-acute COVID-19 syndrome'), ('3ybiysp4', '[Image: see text] Wastewater-based epidemiology may be useful for informing public health response to viral diseases like COVID-19 caused by SARS-CoV-2. We quantified SARS-CoV-2 RNA in wastewater influent and primary settled solids in two wastewater treatment plants to inform the preanalytical and analytical approaches and to assess whether influent or solids harbored more viral targets. The primary settled solids samples resulted in higher SARS-CoV-2 detection frequencies than the corresponding influent samples. Likewise, SARS-CoV-2 RNA was more readily detected in solids using one-step digital droplet (dd)RT-PCR than with two-step RT-QPCR and two-step ddRT-PCR, likely owing to reduced inhibition with the one-step ddRT-PCR assay. We subsequently analyzed a longitudinal time series of 89 settled solids samples from a single plant for SARS-CoV-2 RNA as well as coronavirus recovery (bovine coronavirus) and fecal strength (pepper mild mottle virus) controls. SARS-CoV-2 RNA targets N1 and N2 concentrations correlated positively and significantly with COVID-19 clinically confirmed case counts in the sewershed. Together, the results demonstrate that measuring SARS-CoV-2 RNA concentrations in settled solids may be a more sensitive approach than measuring SARS-CoV-2 in influent. SARS-CoV-2 RNA in Wastewater Settled Solids Is Associated with COVID-19 Cases in a Large Urban Sewershed')]}, {'tweet_id': 96, 'gold_paper': 'ybwwmyqy', 'retrieved_papers': [('ybwwmyqy', 'Invasive fungal infections pose an important threat to public health and are an under-recognized component of antimicrobial resistance, an emerging crisis worldwide. Across a period of profound global environmental change and expanding at-risk populations, human-infecting pathogenic fungi are evolving resistance to all licensed systemic antifungal drugs. In this Review, we highlight the main mechanisms of antifungal resistance and explore the similarities and differences between bacterial and fungal resistance to antimicrobial control. We discuss the research and innovation topics that are needed for risk reduction strategies aimed at minimizing the emergence of resistance in pathogenic fungi. These topics include links between the environment and One Health, surveillance, diagnostics, routes of transmission, novel therapeutics and methods to mitigate hotspots for fungal adaptation. We emphasize the global efforts required to steward our existing antifungal armamentarium, and to direct the research and development of future therapies and interventions. Tackling the emerging threat of antifungal resistance to human health'), ('ierqfgo5', 'Antimicrobial resistance (AMR) is a critical worldwide health issue that jeopardizes our ability to fight illnesses. However, despite being a natural phenomenon, AMR is exacerbated in the world by inappropriate administration of an antimicrobial medication such as under-use or overuse by the general population, farmers, and various health professionals. The onset of the COVID-19 pandemic has put the world in a shocking state. The pandemic exacerbated the problem of antimicrobial resistance, which was largely caused by irrational off-label use of antivirals, anthelmintics, antimalarials, and, most notably, macrolide antibiotics. As a result, monitoring the AMR progression during the pandemic has been critical. The One Health Approach is progressively becoming the most widely utilized and recommended approach in the ongoing fight against AMR. The aim of this article is to address the lack of teachings in AMR and the One Health Approach in health student training curricula, as well as to provide recommendations that can be implemented as we progress beyond the COVID-19 era. Antimicrobial resistance and one health in the post COVID-19 era: What should health students learn?'), ('qh6rif48', 'Before the coronavirus 2019 (COVID-19) pandemic began, antimicrobial resistance (AMR) was among the top priorities for global public health. Already a complex challenge, AMR now needs to be addressed in a changing healthcare landscape. Here, we analyse how changes due to COVID-19 in terms of antimicrobial usage, infection prevention, and health systems affect the emergence, transmission, and burden of AMR. Increased hand hygiene, decreased international travel, and decreased elective hospital procedures may reduce AMR pathogen selection and spread in the short term. However, the opposite effects may be seen if antibiotics are more widely used as standard healthcare pathways break down. Over 6 months into the COVID-19 pandemic, the dynamics of AMR remain uncertain. We call for the AMR community to keep a global perspective while designing finely tuned surveillance and research to continue to improve our preparedness and response to these intersecting public health challenges. Antimicrobial resistance and COVID-19: Intersections and implications'), ('lzddnb8j', 'Fungal infections represent a global problem, notably for immunocompromised patients in hospital, COVID-19 patient wards and care home settings, and the ever-increasing emergence of multidrug resistant fungal strains is a sword of Damocles hanging over many healthcare systems. Azoles represent the mainstay of antifungal drugs, and their mode of action involves the binding mode of these molecules to the fungal lanosterol 14α-demethylase target enzyme. In this study, we have prepared and characterized four novel organometallic derivatives of the frontline antifungal drug fluconazole (1a–4a). Very importantly, enzyme inhibition and chemogenomic profiling demonstrated that lanosterol 14α-demethylase, as for fluconazole, was the main target of the most active compound of the series, (N-(ferrocenylmethyl)-2-(2,4-difluorophenyl)-2-hydroxy-N-methyl-3-(1H-1,2,4-triazol-1-yl)propan-1-aminium chloride, 2a). Transmission electron microscopy (TEM) studies suggested that 2a induced a loss in cell wall integrity as well as intracellular features ascribable to late apoptosis or necrosis. The impressive activity of 2a was further confirmed on clinical isolates, where antimycotic potency up to 400 times higher than fluconazole was observed. Also, 2a showed activity towards azole-resistant strains. This finding is very interesting since the primary target of 2a is the same as that of fluconazole, emphasizing the role played by the organometallic moiety. In vivo experiments in a mice model of Candida infections revealed that 2a reduced the fungal growth and dissemination but also ameliorated immunopathology, a finding suggesting that 2a is active in vivo with added activity on the host innate immune response. In vivo active organometallic-containing antimycotic agents'), ('ouvq2wpq', 'Aspergillus fumigatus is an opportunistic human pathogen that causes aspergillosis, a spectrum of environmentally acquired respiratory illnesses. It has a cosmopolitan distribution and exists in the environment as a saprotroph on decaying plant matter. Azoles, which target Cyp51A in the ergosterol synthesis pathway, are the primary class of drugs used to treat aspergillosis. Azoles are also used to combat plant pathogenic fungi. Recently, an increasing number of azole-naive patients have presented with pan-azole–resistant strains of A. fumigatus. The TR(34)/L98H and TR(46)/Y121F/T289A alleles in the cyp51A gene are the most common ones conferring pan-azole resistance. There is evidence that these mutations arose in agricultural settings; therefore, numerous studies have been conducted to identify azole resistance in environmental A. fumigatus and to determine where resistance is developing in the environment. Here, we summarize the global occurrence of azole-resistant A. fumigatus in the environment based on available literature. Additionally, we have created an interactive world map showing where resistant isolates have been detected and include information on the specific alleles identified, environmental settings, and azole fungicide use. Azole-resistant A. fumigatus has been found on every continent, except for Antarctica, with the highest number of reports from Europe. Developed environments, specifically hospitals and gardens, were the most common settings where azole-resistant A. fumigatus was detected, followed by soils sampled from agricultural settings. The TR(34)/L98H resistance allele was the most common in all regions except South America where the TR(46)/Y121F/T289A allele was the most common. A major consideration in interpreting this survey of the literature is sampling bias; regions and environments that have been extensively sampled are more likely to show greater azole resistance even though resistance could be more prevalent in areas that are under-sampled or not sampled at all. Increased surveillance to pinpoint reservoirs, as well as antifungal stewardship, is needed to preserve this class of antifungals for crop protection and human health. Azole-resistant Aspergillus fumigatus in the environment: Identifying key reservoirs and hotspots of antifungal resistance')]}]\n",
      "[{'tweet_id': 16, 'gold_paper': '3qvh482o', 'retrieved_papers': [('hg3xpej0', \"BACKGROUND: There is growing concern about possible cognitive consequences of COVID-19, with reports of ‘Long COVID’ symptoms persisting into the chronic phase and case studies revealing neurological problems in severely affected patients. However, there is little information regarding the nature and broader prevalence of cognitive problems post-infection or across the full spread of disease severity. METHODS: We sought to confirm whether there was an association between cross-sectional cognitive performance data from 81,337 participants who between January and December 2020 undertook a clinically validated web-optimized assessment as part of the Great British Intelligence Test, and questionnaire items capturing self-report of suspected and confirmed COVID-19 infection and respiratory symptoms. FINDINGS: People who had recovered from COVID-19, including those no longer reporting symptoms, exhibited significant cognitive deficits versus controls when controlling for age, gender, education level, income, racial-ethnic group, pre-existing medical disorders, tiredness, depression and anxiety. The deficits were of substantial effect size for people who had been hospitalised (N = 192), but also for non-hospitalised cases who had biological confirmation of COVID-19 infection (N = 326). Analysing markers of premorbid intelligence did not support these differences being present prior to infection. Finer grained analysis of performance across sub-tests supported the hypothesis that COVID-19 has a multi-domain impact on human cognition. INTERPRETATION: Interpretation. These results accord with reports of ‘Long Covid’ cognitive symptoms that persist into the early-chronic phase. They should act as a clarion call for further research with longitudinal and neuroimaging cohorts to plot recovery trajectories and identify the biological basis of cognitive deficits in SARS-COV-2 survivors. FUNDING: Funding. AH is supported by the UK Dementia Research Institute Care Research and Technology Centre and Biomedical Research Centre at Imperial College London. WT is supported by the EPSRC Centre for Doctoral Training in Neurotechnology. SRC is funded by a Wellcome Trust Clinical Fellowship 110,049/Z/15/Z. JMB is supported by Medical Research Council (MR/N013700/1). MAM, SCRW and PJH are, in part, supported by the National Institute for Health Research (NIHR) Biomedical Research Centre at South London and Maudsley NHS Foundation Trust and King's College London Cognitive deficits in people who have recovered from COVID-19\")]}, {'tweet_id': 69, 'gold_paper': 'r58aohnu', 'retrieved_papers': [('r58aohnu', 'On May 12, 2020 (day 0), a hair stylist at salon A in Springfield, Missouri (stylist A), developed respiratory symptoms and continued working with clients until day 8, when the stylist received a positive test result for SARS-CoV-2, the virus that causes coronavirus disease 2019 (COVID-19). A second hair stylist (stylist B), who had been exposed to stylist A, developed respiratory symptoms on May 15, 2020 (day 3), and worked with clients at salon A until day 8 before seeking testing for SARS-CoV-2, which returned a positive result on day 10. A total of 139 clients were directly serviced by stylists A and B from the time they developed symptoms until they took leave from work. Stylists A and B and the 139 clients followed the City of Springfield ordinance* and salon A policy recommending the use of face coverings (i.e., surgical masks, N95 respirators,† or cloth face coverings) for both stylists and clients during their interactions. Other stylists at salon A who worked closely with stylists A and B were identified, quarantined, and monitored daily for 14 days after their last exposure to stylists A or B. None of these stylists reported COVID-19 symptoms. After stylist B received a positive test result on day 10, salon A closed for 3 days to disinfect frequently touched and contaminated areas. After public health contact tracings and 2 weeks of follow-up, no COVID-19 symptoms were identified among the 139 exposed clients or their secondary contacts. The citywide ordinance and company policy might have played a role in preventing spread of SARS-CoV-2 during these exposures. These findings support the role of source control in preventing transmission and can inform the development of public health policy during the COVID-19 pandemic. As stay-at-home orders are lifted, professional and social interactions in the community will present more opportunities for spread of SARS-CoV-2. Broader implementation of masking policies could mitigate the spread of infection in the general population. Absence of Apparent Transmission of SARS-CoV-2 from Two Stylists After Exposure at a Hair Salon with a Universal Face Covering Policy - Springfield, Missouri, May 2020.')]}, {'tweet_id': 73, 'gold_paper': 'sts48u9i', 'retrieved_papers': [('9x1d1kp1', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has rapidly spread within the human population. Although SARS-CoV-2 is a novel coronavirus, most humans had been previously exposed to other antigenically distinct common seasonal human coronaviruses (hCoVs) before the COVID-19 pandemic. Here, we quantified levels of SARS-CoV-2-reactive antibodies and hCoV-reactive antibodies in serum samples collected from 204 humans before the COVID-19 pandemic. We then quantified pre-pandemic antibody levels in serum from a separate cohort of 252 individuals who became PCR-confirmed infected with SARS-CoV-2. Finally, we longitudinally measured hCoV and SARS-CoV-2 antibodies in the serum of hospitalized COVID-19 patients. Our studies indicate that most individuals possessed hCoV-reactive antibodies before the COVID-19 pandemic. We determined that ~23% of these individuals possessed non-neutralizing antibodies that cross-reacted with SARS-CoV-2 spike and nucleocapsid proteins. These antibodies were not associated with protection against SARS-CoV-2 infections or hospitalizations, but paradoxically these hCoV cross-reactive antibodies were boosted upon SARS-CoV-2 infection. Seasonal human coronavirus antibodies are boosted upon SARS-CoV-2 infection but not associated with protection')]}, {'tweet_id': 93, 'gold_paper': '3sr2exq9', 'retrieved_papers': [('3sr2exq9', 'OBJECTIVE: The study objective was to compare gut microbiome diversity and composition in SARS-CoV-2 PCR-positive patients whose symptoms ranged from asymptomatic to severe versus PCR-negative exposed controls. DESIGN: Using a cross-sectional design, we performed shotgun next-generation sequencing on stool samples to evaluate gut microbiome composition and diversity in both patients with SARS-CoV-2 PCR-confirmed infections, which had presented to Ventura Clinical Trials for care from March 2020 through October 2021 and SARS-CoV-2 PCR-negative exposed controls. Patients were classified as being asymptomatic or having mild, moderate or severe symptoms based on National Institute of Health criteria. Exposed controls were individuals with prolonged or repeated close contact with patients with SARS-CoV-2 infection or their samples, for example, household members of patients or frontline healthcare workers. Microbiome diversity and composition were compared between patients and exposed controls at all taxonomic levels. RESULTS: Compared with controls (n=20), severely symptomatic SARS-CoV-2-infected patients (n=28) had significantly less bacterial diversity (Shannon Index, p=0.0499; Simpson Index, p=0.0581), and positive patients overall had lower relative abundances of Bifidobacterium (p<0.0001), Faecalibacterium (p=0.0077) and Roseburium (p=0.0327), while having increased Bacteroides (p=0.0075). Interestingly, there was an inverse association between disease severity and abundance of the same bacteria. CONCLUSION: We hypothesise that low bacterial diversity and depletion of Bifidobacterium genera either before or after infection led to reduced proimmune function, thereby allowing SARS-CoV-2 infection to become symptomatic. This particular dysbiosis pattern may be a susceptibility marker for symptomatic severity from SARS-CoV-2 infection and may be amenable to preinfection, intrainfection or postinfection intervention. TRIAL REGISTRATION NUMBER: NCT04031469 (PCR−) and 04359836 (PCR+). Lost microbes of COVID-19: Bifidobacterium, Faecalibacterium depletion and decreased microbiome diversity associated with SARS-CoV-2 infection severity')]}, {'tweet_id': 96, 'gold_paper': 'ybwwmyqy', 'retrieved_papers': [('ybwwmyqy', 'Invasive fungal infections pose an important threat to public health and are an under-recognized component of antimicrobial resistance, an emerging crisis worldwide. Across a period of profound global environmental change and expanding at-risk populations, human-infecting pathogenic fungi are evolving resistance to all licensed systemic antifungal drugs. In this Review, we highlight the main mechanisms of antifungal resistance and explore the similarities and differences between bacterial and fungal resistance to antimicrobial control. We discuss the research and innovation topics that are needed for risk reduction strategies aimed at minimizing the emergence of resistance in pathogenic fungi. These topics include links between the environment and One Health, surveillance, diagnostics, routes of transmission, novel therapeutics and methods to mitigate hotspots for fungal adaptation. We emphasize the global efforts required to steward our existing antifungal armamentarium, and to direct the research and development of future therapies and interventions. Tackling the emerging threat of antifungal resistance to human health')]}]\n",
      "[{'tweet_id': 16, 'gold_paper': '3qvh482o', 'retrieved_papers': []}, {'tweet_id': 69, 'gold_paper': 'r58aohnu', 'retrieved_papers': []}, {'tweet_id': 73, 'gold_paper': 'sts48u9i', 'retrieved_papers': []}, {'tweet_id': 93, 'gold_paper': '3sr2exq9', 'retrieved_papers': []}, {'tweet_id': 96, 'gold_paper': 'ybwwmyqy', 'retrieved_papers': []}]\n"
     ]
    }
   ],
   "source": [
    "print(all_results[:5])\n",
    "print(vector_results[:5])\n",
    "print(text_results[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
