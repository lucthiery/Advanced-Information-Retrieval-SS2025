    MODEL - MRR@5 - Tokenlimit - comment

2.1 SBERT - 0.4620 - 512 tokens - no loss implementation for now
2.2 TXT-EM-3-LARGE OPEN AI - 0.71 - 8,192 tokens - API-based, zero-shot
2.3 granite-embedding-278m-multilingual	?	8192	Multilingual, IBM Granite family


ideas:
- nomic-ai/nomic-embed-text-v1 - 8192 tokens
- thenlper/gte-large - 2048 tokens 


